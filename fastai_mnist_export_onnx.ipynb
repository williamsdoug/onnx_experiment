{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastai MNIST Model Export\n",
    "\n",
    "Uses standard MNist example as basis to create model that can be exported from Fastai V1 to Tensorflow\n",
    "\n",
    "References:\n",
    "- https://pytorch.org/docs/stable/onnx.html\n",
    "- https://github.com/onnx/tutorials\n",
    "- https://forums.fast.ai/t/saving-model-from-fastai-and-load-it-in-pytorch/18829/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fastai.vision import *   # Quick access to computer vision functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = models.resnet18\n",
    "OUTPUT_NAME = 'mnist_resnet18.onnx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learner_to_ONNX(learner, output_name, verbose=True):\n",
    "    input_size = list(learner.data.x.get(0).shape)\n",
    "    model = learner.model\n",
    "    \n",
    "    if verbose:\n",
    "        print(model)\n",
    "    \n",
    "    dummy_input = torch.randn(10, *input_size)\n",
    "    torch.onnx.export(model.cpu(), dummy_input, output_name, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/ddwil/.fastai/data/mnist_sample')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (12396 items)\n",
       "x: ImageList\n",
       "Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28)\n",
       "y: CategoryList\n",
       "3,3,3,3,3\n",
       "Path: C:\\Users\\ddwil\\.fastai\\data\\mnist_sample;\n",
       "\n",
       "Valid: LabelList (2038 items)\n",
       "x: ImageList\n",
       "Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28)\n",
       "y: CategoryList\n",
       "3,3,3,3,3\n",
       "Path: C:\\Users\\ddwil\\.fastai\\data\\mnist_sample;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ImageDataBunch.from_folder(path, ds_tfms=(rand_pad(2, 28), []), bs=64)\n",
    "data.normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.050794</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>0.995584</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = cnn_learner(data, MODEL_NAME, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model in ONNX Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): AdaptiveConcatPool2d(\n",
      "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
      "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
      "    )\n",
      "    (1): Flatten()\n",
      "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.25)\n",
      "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.5)\n",
      "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "graph(%0 : Float(10, 3, 28, 28),\n",
      "      %0.0.weight : Float(64, 3, 7, 7),\n",
      "      %0.1.weight : Float(64),\n",
      "      %0.1.bias : Float(64),\n",
      "      %0.1.running_mean : Float(64),\n",
      "      %0.1.running_var : Float(64),\n",
      "      %0.1.num_batches_tracked : Long(),\n",
      "      %0.4.0.conv1.weight : Float(64, 64, 3, 3),\n",
      "      %0.4.0.bn1.weight : Float(64),\n",
      "      %0.4.0.bn1.bias : Float(64),\n",
      "      %0.4.0.bn1.running_mean : Float(64),\n",
      "      %0.4.0.bn1.running_var : Float(64),\n",
      "      %0.4.0.bn1.num_batches_tracked : Long(),\n",
      "      %0.4.0.conv2.weight : Float(64, 64, 3, 3),\n",
      "      %0.4.0.bn2.weight : Float(64),\n",
      "      %0.4.0.bn2.bias : Float(64),\n",
      "      %0.4.0.bn2.running_mean : Float(64),\n",
      "      %0.4.0.bn2.running_var : Float(64),\n",
      "      %0.4.0.bn2.num_batches_tracked : Long(),\n",
      "      %0.4.1.conv1.weight : Float(64, 64, 3, 3),\n",
      "      %0.4.1.bn1.weight : Float(64),\n",
      "      %0.4.1.bn1.bias : Float(64),\n",
      "      %0.4.1.bn1.running_mean : Float(64),\n",
      "      %0.4.1.bn1.running_var : Float(64),\n",
      "      %0.4.1.bn1.num_batches_tracked : Long(),\n",
      "      %0.4.1.conv2.weight : Float(64, 64, 3, 3),\n",
      "      %0.4.1.bn2.weight : Float(64),\n",
      "      %0.4.1.bn2.bias : Float(64),\n",
      "      %0.4.1.bn2.running_mean : Float(64),\n",
      "      %0.4.1.bn2.running_var : Float(64),\n",
      "      %0.4.1.bn2.num_batches_tracked : Long(),\n",
      "      %0.5.0.conv1.weight : Float(128, 64, 3, 3),\n",
      "      %0.5.0.bn1.weight : Float(128),\n",
      "      %0.5.0.bn1.bias : Float(128),\n",
      "      %0.5.0.bn1.running_mean : Float(128),\n",
      "      %0.5.0.bn1.running_var : Float(128),\n",
      "      %0.5.0.bn1.num_batches_tracked : Long(),\n",
      "      %0.5.0.conv2.weight : Float(128, 128, 3, 3),\n",
      "      %0.5.0.bn2.weight : Float(128),\n",
      "      %0.5.0.bn2.bias : Float(128),\n",
      "      %0.5.0.bn2.running_mean : Float(128),\n",
      "      %0.5.0.bn2.running_var : Float(128),\n",
      "      %0.5.0.bn2.num_batches_tracked : Long(),\n",
      "      %0.5.0.downsample.0.weight : Float(128, 64, 1, 1),\n",
      "      %0.5.0.downsample.1.weight : Float(128),\n",
      "      %0.5.0.downsample.1.bias : Float(128),\n",
      "      %0.5.0.downsample.1.running_mean : Float(128),\n",
      "      %0.5.0.downsample.1.running_var : Float(128),\n",
      "      %0.5.0.downsample.1.num_batches_tracked : Long(),\n",
      "      %0.5.1.conv1.weight : Float(128, 128, 3, 3),\n",
      "      %0.5.1.bn1.weight : Float(128),\n",
      "      %0.5.1.bn1.bias : Float(128),\n",
      "      %0.5.1.bn1.running_mean : Float(128),\n",
      "      %0.5.1.bn1.running_var : Float(128),\n",
      "      %0.5.1.bn1.num_batches_tracked : Long(),\n",
      "      %0.5.1.conv2.weight : Float(128, 128, 3, 3),\n",
      "      %0.5.1.bn2.weight : Float(128),\n",
      "      %0.5.1.bn2.bias : Float(128),\n",
      "      %0.5.1.bn2.running_mean : Float(128),\n",
      "      %0.5.1.bn2.running_var : Float(128),\n",
      "      %0.5.1.bn2.num_batches_tracked : Long(),\n",
      "      %0.6.0.conv1.weight : Float(256, 128, 3, 3),\n",
      "      %0.6.0.bn1.weight : Float(256),\n",
      "      %0.6.0.bn1.bias : Float(256),\n",
      "      %0.6.0.bn1.running_mean : Float(256),\n",
      "      %0.6.0.bn1.running_var : Float(256),\n",
      "      %0.6.0.bn1.num_batches_tracked : Long(),\n",
      "      %0.6.0.conv2.weight : Float(256, 256, 3, 3),\n",
      "      %0.6.0.bn2.weight : Float(256),\n",
      "      %0.6.0.bn2.bias : Float(256),\n",
      "      %0.6.0.bn2.running_mean : Float(256),\n",
      "      %0.6.0.bn2.running_var : Float(256),\n",
      "      %0.6.0.bn2.num_batches_tracked : Long(),\n",
      "      %0.6.0.downsample.0.weight : Float(256, 128, 1, 1),\n",
      "      %0.6.0.downsample.1.weight : Float(256),\n",
      "      %0.6.0.downsample.1.bias : Float(256),\n",
      "      %0.6.0.downsample.1.running_mean : Float(256),\n",
      "      %0.6.0.downsample.1.running_var : Float(256),\n",
      "      %0.6.0.downsample.1.num_batches_tracked : Long(),\n",
      "      %0.6.1.conv1.weight : Float(256, 256, 3, 3),\n",
      "      %0.6.1.bn1.weight : Float(256),\n",
      "      %0.6.1.bn1.bias : Float(256),\n",
      "      %0.6.1.bn1.running_mean : Float(256),\n",
      "      %0.6.1.bn1.running_var : Float(256),\n",
      "      %0.6.1.bn1.num_batches_tracked : Long(),\n",
      "      %0.6.1.conv2.weight : Float(256, 256, 3, 3),\n",
      "      %0.6.1.bn2.weight : Float(256),\n",
      "      %0.6.1.bn2.bias : Float(256),\n",
      "      %0.6.1.bn2.running_mean : Float(256),\n",
      "      %0.6.1.bn2.running_var : Float(256),\n",
      "      %0.6.1.bn2.num_batches_tracked : Long(),\n",
      "      %0.7.0.conv1.weight : Float(512, 256, 3, 3),\n",
      "      %0.7.0.bn1.weight : Float(512),\n",
      "      %0.7.0.bn1.bias : Float(512),\n",
      "      %0.7.0.bn1.running_mean : Float(512),\n",
      "      %0.7.0.bn1.running_var : Float(512),\n",
      "      %0.7.0.bn1.num_batches_tracked : Long(),\n",
      "      %0.7.0.conv2.weight : Float(512, 512, 3, 3),\n",
      "      %0.7.0.bn2.weight : Float(512),\n",
      "      %0.7.0.bn2.bias : Float(512),\n",
      "      %0.7.0.bn2.running_mean : Float(512),\n",
      "      %0.7.0.bn2.running_var : Float(512),\n",
      "      %0.7.0.bn2.num_batches_tracked : Long(),\n",
      "      %0.7.0.downsample.0.weight : Float(512, 256, 1, 1),\n",
      "      %0.7.0.downsample.1.weight : Float(512),\n",
      "      %0.7.0.downsample.1.bias : Float(512),\n",
      "      %0.7.0.downsample.1.running_mean : Float(512),\n",
      "      %0.7.0.downsample.1.running_var : Float(512),\n",
      "      %0.7.0.downsample.1.num_batches_tracked : Long(),\n",
      "      %0.7.1.conv1.weight : Float(512, 512, 3, 3),\n",
      "      %0.7.1.bn1.weight : Float(512),\n",
      "      %0.7.1.bn1.bias : Float(512),\n",
      "      %0.7.1.bn1.running_mean : Float(512),\n",
      "      %0.7.1.bn1.running_var : Float(512),\n",
      "      %0.7.1.bn1.num_batches_tracked : Long(),\n",
      "      %0.7.1.conv2.weight : Float(512, 512, 3, 3),\n",
      "      %0.7.1.bn2.weight : Float(512),\n",
      "      %0.7.1.bn2.bias : Float(512),\n",
      "      %0.7.1.bn2.running_mean : Float(512),\n",
      "      %0.7.1.bn2.running_var : Float(512),\n",
      "      %0.7.1.bn2.num_batches_tracked : Long(),\n",
      "      %1.2.weight : Float(1024),\n",
      "      %1.2.bias : Float(1024),\n",
      "      %1.2.running_mean : Float(1024),\n",
      "      %1.2.running_var : Float(1024),\n",
      "      %1.2.num_batches_tracked : Long(),\n",
      "      %1.4.weight : Float(512, 1024),\n",
      "      %1.4.bias : Float(512),\n",
      "      %1.6.weight : Float(512),\n",
      "      %1.6.bias : Float(512),\n",
      "      %1.6.running_mean : Float(512),\n",
      "      %1.6.running_var : Float(512),\n",
      "      %1.6.num_batches_tracked : Long(),\n",
      "      %1.8.weight : Float(2, 512),\n",
      "      %1.8.bias : Float(2)):\n",
      "  %135 : Float(10, 64, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%0, %0.0.weight), scope: Sequential/Sequential[0]/Conv2d[0]\n",
      "  %136 : Float(10, 64, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%135, %0.1.weight, %0.1.bias, %0.1.running_mean, %0.1.running_var), scope: Sequential/Sequential[0]/BatchNorm2d[1]\n",
      "  %137 : Float(10, 64, 14, 14) = onnx::Relu(%136), scope: Sequential/Sequential[0]/ReLU[2]\n",
      "  %138 : Float(10, 64, 7, 7) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%137), scope: Sequential/Sequential[0]/MaxPool2d[3]\n",
      "  %139 : Float(10, 64, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%138, %0.4.0.conv1.weight), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %140 : Float(10, 64, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%139, %0.4.0.bn1.weight, %0.4.0.bn1.bias, %0.4.0.bn1.running_mean, %0.4.0.bn1.running_var), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %141 : Float(10, 64, 7, 7) = onnx::Relu(%140), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[0]/ReLU[relu]\n",
      "  %142 : Float(10, 64, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%141, %0.4.0.conv2.weight), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %143 : Float(10, 64, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%142, %0.4.0.bn2.weight, %0.4.0.bn2.bias, %0.4.0.bn2.running_mean, %0.4.0.bn2.running_var), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %144 : Float(10, 64, 7, 7) = onnx::Add(%143, %138), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[0]\n",
      "  %145 : Float(10, 64, 7, 7) = onnx::Relu(%144), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[0]/ReLU[relu]\n",
      "  %146 : Float(10, 64, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%145, %0.4.1.conv1.weight), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %147 : Float(10, 64, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%146, %0.4.1.bn1.weight, %0.4.1.bn1.bias, %0.4.1.bn1.running_mean, %0.4.1.bn1.running_var), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %148 : Float(10, 64, 7, 7) = onnx::Relu(%147), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[1]/ReLU[relu]\n",
      "  %149 : Float(10, 64, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%148, %0.4.1.conv2.weight), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %150 : Float(10, 64, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%149, %0.4.1.bn2.weight, %0.4.1.bn2.bias, %0.4.1.bn2.running_mean, %0.4.1.bn2.running_var), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %151 : Float(10, 64, 7, 7) = onnx::Add(%150, %145), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[1]\n",
      "  %152 : Float(10, 64, 7, 7) = onnx::Relu(%151), scope: Sequential/Sequential[0]/Sequential[4]/BasicBlock[1]/ReLU[relu]\n",
      "  %153 : Float(10, 128, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%152, %0.5.0.conv1.weight), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %154 : Float(10, 128, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%153, %0.5.0.bn1.weight, %0.5.0.bn1.bias, %0.5.0.bn1.running_mean, %0.5.0.bn1.running_var), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %155 : Float(10, 128, 4, 4) = onnx::Relu(%154), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[0]/ReLU[relu]\n",
      "  %156 : Float(10, 128, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%155, %0.5.0.conv2.weight), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %157 : Float(10, 128, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%156, %0.5.0.bn2.weight, %0.5.0.bn2.bias, %0.5.0.bn2.running_mean, %0.5.0.bn2.running_var), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %158 : Float(10, 128, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%152, %0.5.0.downsample.0.weight), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %159 : Float(10, 128, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%158, %0.5.0.downsample.1.weight, %0.5.0.downsample.1.bias, %0.5.0.downsample.1.running_mean, %0.5.0.downsample.1.running_var), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %160 : Float(10, 128, 4, 4) = onnx::Add(%157, %159), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[0]\n",
      "  %161 : Float(10, 128, 4, 4) = onnx::Relu(%160), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[0]/ReLU[relu]\n",
      "  %162 : Float(10, 128, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%161, %0.5.1.conv1.weight), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %163 : Float(10, 128, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%162, %0.5.1.bn1.weight, %0.5.1.bn1.bias, %0.5.1.bn1.running_mean, %0.5.1.bn1.running_var), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %164 : Float(10, 128, 4, 4) = onnx::Relu(%163), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[1]/ReLU[relu]\n",
      "  %165 : Float(10, 128, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%164, %0.5.1.conv2.weight), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %166 : Float(10, 128, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%165, %0.5.1.bn2.weight, %0.5.1.bn2.bias, %0.5.1.bn2.running_mean, %0.5.1.bn2.running_var), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %167 : Float(10, 128, 4, 4) = onnx::Add(%166, %161), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[1]\n",
      "  %168 : Float(10, 128, 4, 4) = onnx::Relu(%167), scope: Sequential/Sequential[0]/Sequential[5]/BasicBlock[1]/ReLU[relu]\n",
      "  %169 : Float(10, 256, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%168, %0.6.0.conv1.weight), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %170 : Float(10, 256, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%169, %0.6.0.bn1.weight, %0.6.0.bn1.bias, %0.6.0.bn1.running_mean, %0.6.0.bn1.running_var), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %171 : Float(10, 256, 2, 2) = onnx::Relu(%170), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[0]/ReLU[relu]\n",
      "  %172 : Float(10, 256, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%171, %0.6.0.conv2.weight), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %173 : Float(10, 256, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%172, %0.6.0.bn2.weight, %0.6.0.bn2.bias, %0.6.0.bn2.running_mean, %0.6.0.bn2.running_var), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %174 : Float(10, 256, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%168, %0.6.0.downsample.0.weight), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %175 : Float(10, 256, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%174, %0.6.0.downsample.1.weight, %0.6.0.downsample.1.bias, %0.6.0.downsample.1.running_mean, %0.6.0.downsample.1.running_var), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %176 : Float(10, 256, 2, 2) = onnx::Add(%173, %175), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[0]\n",
      "  %177 : Float(10, 256, 2, 2) = onnx::Relu(%176), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[0]/ReLU[relu]\n",
      "  %178 : Float(10, 256, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%177, %0.6.1.conv1.weight), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %179 : Float(10, 256, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%178, %0.6.1.bn1.weight, %0.6.1.bn1.bias, %0.6.1.bn1.running_mean, %0.6.1.bn1.running_var), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %180 : Float(10, 256, 2, 2) = onnx::Relu(%179), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[1]/ReLU[relu]\n",
      "  %181 : Float(10, 256, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%180, %0.6.1.conv2.weight), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %182 : Float(10, 256, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%181, %0.6.1.bn2.weight, %0.6.1.bn2.bias, %0.6.1.bn2.running_mean, %0.6.1.bn2.running_var), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %183 : Float(10, 256, 2, 2) = onnx::Add(%182, %177), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[1]\n",
      "  %184 : Float(10, 256, 2, 2) = onnx::Relu(%183), scope: Sequential/Sequential[0]/Sequential[6]/BasicBlock[1]/ReLU[relu]\n",
      "  %185 : Float(10, 512, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%184, %0.7.0.conv1.weight), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %186 : Float(10, 512, 1, 1) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%185, %0.7.0.bn1.weight, %0.7.0.bn1.bias, %0.7.0.bn1.running_mean, %0.7.0.bn1.running_var), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %187 : Float(10, 512, 1, 1) = onnx::Relu(%186), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[0]/ReLU[relu]\n",
      "  %188 : Float(10, 512, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%187, %0.7.0.conv2.weight), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %189 : Float(10, 512, 1, 1) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%188, %0.7.0.bn2.weight, %0.7.0.bn2.bias, %0.7.0.bn2.running_mean, %0.7.0.bn2.running_var), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %190 : Float(10, 512, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%184, %0.7.0.downsample.0.weight), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %191 : Float(10, 512, 1, 1) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%190, %0.7.0.downsample.1.weight, %0.7.0.downsample.1.bias, %0.7.0.downsample.1.running_mean, %0.7.0.downsample.1.running_var), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %192 : Float(10, 512, 1, 1) = onnx::Add(%189, %191), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[0]\n",
      "  %193 : Float(10, 512, 1, 1) = onnx::Relu(%192), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[0]/ReLU[relu]\n",
      "  %194 : Float(10, 512, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%193, %0.7.1.conv1.weight), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %195 : Float(10, 512, 1, 1) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%194, %0.7.1.bn1.weight, %0.7.1.bn1.bias, %0.7.1.bn1.running_mean, %0.7.1.bn1.running_var), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %196 : Float(10, 512, 1, 1) = onnx::Relu(%195), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[1]/ReLU[relu]\n",
      "  %197 : Float(10, 512, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%196, %0.7.1.conv2.weight), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %198 : Float(10, 512, 1, 1) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%197, %0.7.1.bn2.weight, %0.7.1.bn2.bias, %0.7.1.bn2.running_mean, %0.7.1.bn2.running_var), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %199 : Float(10, 512, 1, 1) = onnx::Add(%198, %193), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[1]\n",
      "  %200 : Float(10, 512, 1, 1) = onnx::Relu(%199), scope: Sequential/Sequential[0]/Sequential[7]/BasicBlock[1]/ReLU[relu]\n",
      "  %201 : Float(10, 512, 1, 1) = onnx::MaxPool[kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%200), scope: Sequential/Sequential[1]/AdaptiveConcatPool2d[0]/AdaptiveMaxPool2d[mp]\n",
      "  %202 : Float(10, 512, 1, 1) = onnx::GlobalAveragePool(%200), scope: Sequential/Sequential[1]/AdaptiveConcatPool2d[0]/AdaptiveAvgPool2d[ap]\n",
      "  %203 : Float(10, 1024, 1, 1) = onnx::Concat[axis=1](%201, %202), scope: Sequential/Sequential[1]/AdaptiveConcatPool2d[0]\n",
      "  %204 : Long() = onnx::Constant[value={0}](), scope: Sequential/Sequential[1]/Flatten[1]\n",
      "  %205 : Tensor = onnx::Shape(%203), scope: Sequential/Sequential[1]/Flatten[1]\n",
      "  %206 : Long() = onnx::Gather[axis=0](%205, %204), scope: Sequential/Sequential[1]/Flatten[1]\n",
      "  %207 : Long() = onnx::Constant[value={-1}](), scope: Sequential/Sequential[1]/Flatten[1]\n",
      "  %208 : Tensor = onnx::Unsqueeze[axes=[0]](%206)\n",
      "  %209 : Tensor = onnx::Unsqueeze[axes=[0]](%207)\n",
      "  %210 : Tensor = onnx::Concat[axis=0](%208, %209)\n",
      "  %211 : Float(10, 1024) = onnx::Reshape(%203, %210), scope: Sequential/Sequential[1]/Flatten[1]\n",
      "  %212 : Tensor = onnx::Unsqueeze[axes=[2]](%211), scope: Sequential/Sequential[1]/BatchNorm1d[2]\n",
      "  %213 : Tensor = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%212, %1.2.weight, %1.2.bias, %1.2.running_mean, %1.2.running_var), scope: Sequential/Sequential[1]/BatchNorm1d[2]\n",
      "  %214 : Float(10, 1024) = onnx::Squeeze[axes=[2]](%213), scope: Sequential/Sequential[1]/Dropout[3]\n",
      "  %215 : Float(10, 512) = onnx::Gemm[alpha=1, beta=1, transB=1](%214, %1.4.weight, %1.4.bias), scope: Sequential/Sequential[1]/Dropout[3]\n",
      "  %216 : Float(10, 512) = onnx::Relu(%215), scope: Sequential/Sequential[1]/ReLU[5]\n",
      "  %217 : Tensor = onnx::Unsqueeze[axes=[2]](%216), scope: Sequential/Sequential[1]/BatchNorm1d[6]\n",
      "  %218 : Tensor = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%217, %1.6.weight, %1.6.bias, %1.6.running_mean, %1.6.running_var), scope: Sequential/Sequential[1]/BatchNorm1d[6]\n",
      "  %219 : Float(10, 512) = onnx::Squeeze[axes=[2]](%218), scope: Sequential/Sequential[1]/Dropout[7]\n",
      "  %220 : Float(10, 2) = onnx::Gemm[alpha=1, beta=1, transB=1](%219, %1.8.weight, %1.8.bias), scope: Sequential/Sequential[1]/Dropout[7]\n",
      "  return (%220)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learner_to_ONNX(learn, OUTPUT_NAME, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 1E07-29AE\n",
      "\n",
      " Directory of C:\\Users\\ddwil\\Documents\\GitHub\\onnx_experiment\n",
      "\n",
      "08/15/2019  10:17 AM    <DIR>          .\n",
      "08/15/2019  10:17 AM    <DIR>          ..\n",
      "08/15/2019  09:43 AM             1,307 .gitignore\n",
      "08/15/2019  09:47 AM    <DIR>          .ipynb_checkpoints\n",
      "08/14/2019  04:05 PM            68,223 fastai-Export.ipynb\n",
      "08/15/2019  09:56 AM        46,889,594 mnist.onnx\n",
      "08/15/2019  10:17 AM             6,685 mnist_fastai.ipynb\n",
      "08/15/2019  10:17 AM        46,889,594 mnist_resnet18.onnx\n",
      "08/14/2019  05:55 PM            70,687 onnx2tf.ipynb\n",
      "08/15/2019  09:43 AM                17 README.md\n",
      "               7 File(s)     93,926,107 bytes\n",
      "               3 Dir(s)  146,226,114,560 bytes free\n"
     ]
    }
   ],
   "source": [
    "#!ls\n",
    "!dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
